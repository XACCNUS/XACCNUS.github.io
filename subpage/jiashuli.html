<html>
<link rel="stylesheet" type="text/css" href="../graph-style.css">

<h1 id="flashtvm-optimizing-deep-learning-computation-on-opencl-compatible-hardware-accelerators">FlashTVM: Optimizing Deep Learning Computation on OpenCL-compatible Hardware Accelerators</h1>
<h2 id="abstract-">Abstract:</h2>
<p>TVM is an end-to-end Deep Learning Compiler Stack, it exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. The Versatile Tensor Accelerator (VTA) is an extension of the Apache(incubating) TVM framework that exposes a RISC-like programming abstraction to describe compute and memory operations at the tensor level. The original VTA core only works on selected Xilinx Edge SoC FPGAs. Limited by hardware resources available, the performance of the current VTA core is unable to support demanding applications. At 4Paradigm, we designed and implemented a interface framework providing TVM-VTA the ability to utilize OpenCL-compatible Hardware Accelerators, including Intel and Xilinx&#39;s high-performance datacenter FPGAs.</p>
